{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edf6b43-5c77-43f5-a179-9986fc68abf8",
   "metadata": {},
   "source": [
    "# Esame di Metodi Numerici - 6 Luglio 2023\n",
    "## Turno II -- Ore 11.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dd546-5e8d-4dde-ab61-51251c05bad2",
   "metadata": {},
   "source": [
    "## Esercizio 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378dc3b4-702c-4e2f-b388-fc5275db9a75",
   "metadata": {},
   "source": [
    "Nel file ``Test_II.mat`` sono memorizzate le matrici A1, A2 ed A3 ed i vettori b1,b2,b3. Risolvere i 3 sistemi lineari aventi ciascuno di essi come matrice dei coefficienti A1 e termine noto b1, A2 e termine noto b2, A3 e terimine noto b3  utilizzando il metodo più adatto per ciascuno di essi e  commentare i risultati ottenuti  giustificandoli alla luce della teoria.\n",
    "Verificare se le matrici sono malcondizionate, dire teoricamente cosa questo implica e verificarlo sperimentalmente.\n",
    "\n",
    "\n",
    "Per la lettura dei dati procedere nel seguente modo:\n",
    "\n",
    "``from scipy.io import loadmat``\n",
    "\n",
    "``import numpy as np``\n",
    "\n",
    "``dati = loadmat('Test_II.mat')``\n",
    "\n",
    "``A1=dati[\"A1\"] ``\n",
    "\n",
    "``A1=A1.astype(float)``\n",
    "\n",
    "`` b1=dati[\"b1\"] ``\n",
    "\n",
    "`` b1=b1.astype(float)``\n",
    "\n",
    "``A2=dati[\"A2\"] ``\n",
    "\n",
    "``A2=A2.astype(float)``\n",
    "\n",
    "`` b2=dati[\"b2\"] ``\n",
    "\n",
    "`` b2=b2.astype(float)``\n",
    "\n",
    "``A3=dati[\"A3\"] ``\n",
    "\n",
    "``A3=A3.astype(float)``\n",
    "\n",
    "`` b3=dati[\"b3\"] ``\n",
    "\n",
    "`` b3=b3.astype(float)``\n",
    "\n",
    "\n",
    "\n",
    "                                                                    Punti 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0189b-b53c-4ad7-b7a7-d5af0de1ecfc",
   "metadata": {},
   "source": [
    "### Osservazioni\n",
    "#### - Matrice A1\n",
    "La matrice è quadrata, piccola e densa. Quindi, in generale, il sistema lineare associato si presta ad essere risolto con i metodi diretti — che si basano sulla fattorizzazione di $A$ in due matrici, chiamiamole $B$ e $C$.\n",
    "Tra i possibili metodi troviamo:\n",
    "- fattorizzazione di Gauss $L \\cdot U$, dove $L$ è una matrice triangolare inferiore con diagonale a 1 e $U$ triangolare superiore.\n",
    "- fattorizzazione di Householder $Q \\cdot R$, dove $Q$ è una matrice ortogonale e $R$ è triangolare superiore.\n",
    "- fattorizzazione di Cholesky $L \\cdot L^T$ (oppure $R^T \\cdot R$), dove $L$ è una matrice triangolare inferiore con diagonale positiva\n",
    "\n",
    "Tra i tre metodi, quello che sfrutta la caratteristica di A1 di essere definita positiva è Cholesky — che scelgo di implementare.\n",
    "\n",
    "Matrice altamente mal condizionata!\n",
    "\n",
    "#### - Matrice A2\n",
    "La matrice non è quadrata, quindi il sistema associato è un sistema lineare sovradeterminato. La matrice ha rango massimo, quindi sicuramente posso scartare il metodo \"Singular Value Decomposition\" adatto a matrici singolari.\n",
    "\n",
    "La matrice è ben condizionata, quindi il metodo delle Equazioni Normali prevale rispetto a QR Least Squares.\n",
    "\n",
    "#### - Matrice A3\n",
    "Matrice ben condizionata, grande e sparsa, sinonimo di metodi iterativi. Non è definita positiva, ma è a diagonale strettamente dominante — Jacobi è il metodo ideale in questo caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c837c7a-fc8d-4541-9a7d-0315589b6b77",
   "metadata": {},
   "source": [
    "# Esercizio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602927f7-4366-4f99-9fe6-5fb4ee0ece45",
   "metadata": {},
   "source": [
    "Data l'equazione di 2° grado $$\\frac{1}{2} x^2+2bx-c=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ecd58-1419-4a72-9f65-035faa6cbffa",
   "metadata": {},
   "source": [
    "con $b=10^7, c=10^{-i},i=-5,\\cdots,12 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0c800-a638-4df7-b38d-a715ef81f808",
   "metadata": {},
   "source": [
    "- a) Scrivere le due formule algebriche per ricavare i valori delle 2 soluzioni\n",
    "\n",
    "                                                                                    1 punto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b4232-f62d-46b2-83e6-c19496fd56ef",
   "metadata": {},
   "source": [
    "- b) Studiare l'indice di condizionamento delle 2 formule algebriche, facendo uso del risultato teorico visto a lezione riguardo l'indice di condizionamento della valutazione di una funzione. (Spiegare il significato di problema mal condizionato) e dire quale delle due formule è malcondizionata. Per quali valori di $c$ il problema risulta ben condizionato?\n",
    "\n",
    "                                                                                    5 punti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f2364-29da-4c31-8bcf-cb3566dc0dac",
   "metadata": {},
   "source": [
    "- c) Nel caso in cui una delle due formule risulti mal condizionata, proporre una soluzione algebricamente equivalente che non sia malcondizionata.\n",
    "\n",
    "                                                                                    3 punti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8888-3dfe-4ea5-a93b-e0adab565e1b",
   "metadata": {},
   "source": [
    "                                                                        Totale 9 punti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911860d3-45d8-45fc-99f2-bf79c64f1a80",
   "metadata": {},
   "source": [
    "## Domanda intelligenza artificiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f72b3e-3533-4866-bf02-44fea1b7c825",
   "metadata": {},
   "source": [
    " Limiti delle reti MLP (multilayer Perceptron) ed introduzione delle Reti neurali Convoluzionali. \n",
    "- Architettura di una rete neurale convoluzionale: strati convoluzionali, attivazione non lineare e pooling + parte fully connected.\n",
    "- Loss function per il task della regressione.  Training di una rete. \n",
    "- Cenni sull'algoritmo di backpropagation per il calcolo delle derivate parziale della funzione costo rispetto ai pesi ditutti i layer .\n",
    "- Tecniche di Ottimizzazione: metodo di discesa del gradient batch, metodo del gradiente stocastico (SGD) ,metodo del gradiente stocastico minibatch.\n",
    "                                                                                [7  punti]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503e7f7-75e3-4f25-adcd-0a4feff1bf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
